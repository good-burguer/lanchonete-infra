#!/usr/bin/env bash
set -euo pipefail

# ====== Config (permite override por vari√°vel de ambiente) ======
: "${AWS_REGION:=us-east-1}"
: "${TF_BUCKET:=good-burger-tf-state}"
: "${TF_LOCK_TABLE:=good-burger-tf-lock}"
: "${TF_KEY:=infra/terraform.tfstate}"
: "${EKS_NAME:=gb-dev-eks}"                 # fallback caso n√£o haja output no state
: "${EKS_NODEGROUP:=gb-dev-eks-ng}"         # nome padr√£o do nodegroup
: "${APPLY_APP_MANIFESTS:=true}"           # se "true", aplica k8s/app/ ap√≥s recriar o cluster
: "${K8S_NS_DIR:=../../k8s/namespace}"      # diret√≥rio com manifests de Namespace (aplicados sem -n)
: "${K8S_APP_DIR:=../../k8s/app}"           # diret√≥rio com manifests da aplica√ß√£o (aplicados com -n app)
: "${K8S_SYS_DIR:=../../k8s/kube-system}"   # diret√≥rio com manifests do kube-system (aplicados com -n kube-system)
: "${ACCOUNT_ID:=$(aws sts get-caller-identity --query Account --output text 2>/dev/null || true)}"
: "${APP_REPO:=lanchonete-app}"
: "${GIT_SHA:=$(git rev-parse --short HEAD 2>/dev/null || echo dev)}"
: "${APP_TAG:=${GIT_SHA}-amd64}"
: "${APP_IMAGE_URI:=${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${APP_REPO}:${APP_TAG}}"

: "${LB_NAMESPACE:=app}"                 # namespace onde est√° o Service do LB
: "${LB_SERVICE_NAME:=lanchonete-svc}"   # nome do Service (tipo LoadBalancer)
: "${LB_WAIT_TIMEOUT:=300}"              # tempo m√°ximo (segundos) para aparecer o endpoint

get_lb_endpoint() {
  # tenta resolver hostname ou IP do LoadBalancer
  local host ip ep
  host="$(kubectl -n "${LB_NAMESPACE}" get svc "${LB_SERVICE_NAME}" -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null | tr -d '[:space:]')"
  ip="$(kubectl -n "${LB_NAMESPACE}" get svc "${LB_SERVICE_NAME}" -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null | tr -d '[:space:]')"
  if [[ -n "$host" ]]; then
    ep="$host"
  elif [[ -n "$ip" ]]; then
    ep="$ip"
  else
    ep=""
  fi
  printf "%s" "$ep"
}

log() { printf "\n[resume] %s\n" "$*"; }
die() { echo "[resume][erro] $*" >&2; exit 1; }

log "Imagem da aplica√ß√£o (APP_IMAGE_URI): ${APP_IMAGE_URI:-<indefinida>}"

# ====== 0) Terraform init (sempre reconfigure backend S3 + DynamoDB) ======
log "Inicializando Terraform com backend S3 + DynamoDB‚Ä¶"
terraform init -input=false -reconfigure \
  -backend-config="bucket=${TF_BUCKET}" \
  -backend-config="key=${TF_KEY}" \
  -backend-config="region=${AWS_REGION}" \
  -backend-config="dynamodb_table=${TF_LOCK_TABLE}" \
  -backend-config="encrypt=true"

# ====== 1) Terraform apply para (re)criar EKS e depend√™ncias declaradas ======
log "Executando 'terraform apply' para (re)criar o cluster e node group‚Ä¶"
terraform apply -auto-approve -lock-timeout=5m \
  -var="aws_region=${AWS_REGION}" \
  -var="tf_state_bucket=${TF_BUCKET}" \
  -var="tf_lock_table=${TF_LOCK_TABLE}"

# Tenta ler nome do cluster pelo output (se existir)
TF_EKS_OUTPUT="$(terraform output -raw eks_cluster_name 2>/dev/null || true)"
if [[ -n "${TF_EKS_OUTPUT}" ]]; then
  EKS_NAME="${TF_EKS_OUTPUT}"
fi

# ====== 2) Espera EKS ficar ACTIVE e kubeconfig atualizado ======
log "Aguardando EKS ficar ACTIVE‚Ä¶ (${EKS_NAME})"
aws eks wait cluster-active --name "${EKS_NAME}" --region "${AWS_REGION}" || true

log "Atualizando kubeconfig local para o cluster ${EKS_NAME}‚Ä¶"
aws eks update-kubeconfig --name "${EKS_NAME}" --region "${AWS_REGION}" >/dev/null

# ====== 3) Espera NodeGroup ficar ACTIVE (se existir) ======
if aws eks describe-nodegroup \
      --cluster-name "${EKS_NAME}" \
      --nodegroup-name "${EKS_NODEGROUP}" \
      --region "${AWS_REGION}" >/dev/null 2>&1; then
  NG_STATUS="$(aws eks describe-nodegroup \
    --cluster-name "${EKS_NAME}" \
    --nodegroup-name "${EKS_NODEGROUP}" \
    --region "${AWS_REGION}" \
    --query 'nodegroup.status' --output text)"
  log "NodeGroup ${EKS_NODEGROUP} status atual: ${NG_STATUS}. Aguardando ACTIVE‚Ä¶"
  aws eks wait nodegroup-active \
    --cluster-name "${EKS_NAME}" \
    --nodegroup-name "${EKS_NODEGROUP}" \
    --region "${AWS_REGION}" || true
else
  log "NodeGroup ${EKS_NODEGROUP} n√£o encontrado (pode n√£o ser gerenciado por este Terraform)."
fi

# ====== 4) Iniciar RDS se estiver parado ======
log "Verificando estado do RDS (gb-dev-postgres)‚Ä¶"
DB_STATUS="$(aws rds describe-db-instances \
  --db-instance-identifier gb-dev-postgres \
  --region "${AWS_REGION}" \
  --query 'DBInstances[0].DBInstanceStatus' --output text 2>/dev/null || echo 'unknown')"

case "$DB_STATUS" in
  stopped)
    log "RDS est√° 'stopped'. Iniciando inst√¢ncia‚Ä¶"
    aws rds start-db-instance \
      --db-instance-identifier gb-dev-postgres \
      --region "${AWS_REGION}" >/dev/null || true
    log "Aguardando RDS ficar 'available'‚Ä¶"
    aws rds wait db-instance-available \
      --db-instance-identifier gb-dev-postgres \
      --region "${AWS_REGION}" || true
    ;;
  starting|available|backing-up|modifying)
    log "RDS j√° est√° em '${DB_STATUS}'."
    ;;
  *)
    log "Estado do RDS: ${DB_STATUS} (seguindo adiante)."
    ;;
esac

# ====== 5) (Opcional) Aplicar manifests da aplica√ß√£o ======
if [[ "${APPLY_APP_MANIFESTS}" == "true" ]]; then
  # 5.1) Namespace(s) (sem -n)
  if [[ -d "${K8S_NS_DIR}" ]]; then
    log "Aplicando manifests de namespace em ${K8S_NS_DIR}‚Ä¶"
    kubectl apply -f "${K8S_NS_DIR}"
  else
    # fallback: garante pelo menos o namespace app
    kubectl get ns app >/dev/null 2>&1 || kubectl create namespace app
  fi

  # 5.2) App (com -n app)
  if [[ -d "${K8S_APP_DIR}" ]]; then
    log "Aplicando manifests da aplica√ß√£o em ${K8S_APP_DIR} (namespace app)‚Ä¶"
    # 5.2.0) Validar imagem no ECR (auto-fallback para a √∫ltima v√°lida)
    # Se APP_IMAGE_URI n√£o existir no ECR, pega a √∫ltima imagem v√°lida e usa no deploy
    repo_path="${APP_IMAGE_URI%:*}"            # ex: 8226....amazonaws.com/lanchonete-app
    repo_name="${repo_path##*/}"               # ex: lanchonete-app
    tag="${APP_IMAGE_URI##*:}"                 # ex: abc123-amd64

    if ! aws ecr describe-images \
          --repository-name "${repo_name}" \
          --image-ids imageTag="${tag}" \
          --region "${AWS_REGION}" >/dev/null 2>&1; then
      log "Imagem n√£o encontrada no ECR: ${APP_IMAGE_URI}. Buscando √∫ltima tag v√°lida‚Ä¶"

      LATEST_TAG="$(aws ecr describe-images \
        --repository-name "${repo_name}" \
        --region "${AWS_REGION}" \
        --query 'reverse(sort_by(imageDetails,& imagePushedAt))[0].imageTags[0]' \
        --output text 2>/dev/null || true)"

      if [[ -z "${LATEST_TAG}" || "${LATEST_TAG}" == "None" ]]; then
        die "Nenhuma imagem encontrada no ECR (${repo_name}). Construa/publica uma imagem primeiro."
      fi

      APP_IMAGE_URI="${repo_path}:${LATEST_TAG}"
      log "Usando fallback para a imagem mais recente do ECR: ${APP_IMAGE_URI}"
    fi

    # 5.2.1) Renderiza e aplica o Deployment com a imagem parametrizada
    if [[ -f "${K8S_APP_DIR}/deployment.yaml" ]]; then
      log "Renderizando deployment com APP_IMAGE_URI=${APP_IMAGE_URI}‚Ä¶"
      APP_IMAGE_URI="${APP_IMAGE_URI}" envsubst < "${K8S_APP_DIR}/deployment.yaml" | kubectl -n app apply -f -
    else
      log "Arquivo deployment.yaml n√£o encontrado em ${K8S_APP_DIR}."
    fi

    # 5.2.2) Aplica os demais manifests da aplica√ß√£o (exceto o deployment, que j√° foi)
    find "${K8S_APP_DIR}" -type f -name '*.yaml' ! -name 'deployment.yaml' -print0 | xargs -0 -I{} kubectl -n app apply -f {}

    # 5.2.3) Aguarda rollout do deployment (se existir)
    if kubectl -n app get deploy lanchonete-app >/dev/null 2>&1; then
      kubectl -n app rollout status deploy/lanchonete-app || true
      kubectl -n app get deploy lanchonete-app -o=jsonpath='{.spec.template.spec.containers[0].image}{"\n"}' || true
    fi
  else
    log "Diret√≥rio de app n√£o encontrado: ${K8S_APP_DIR} (pulando)."
  fi

  # 5.3) kube-system (com -n kube-system)
  if [[ -d "${K8S_SYS_DIR}" ]]; then
    log "Aplicando manifests do kube-system em ${K8S_SYS_DIR}‚Ä¶"
    # usar server-side para lidar com aws-auth e evitar conflitos de resourceVersion
    find "${K8S_SYS_DIR}" -type f -name '*.yaml' -print0 | xargs -0 -I{} kubectl -n kube-system apply --server-side --force-conflicts -f {}
  else
    log "Diret√≥rio kube-system n√£o encontrado: ${K8S_SYS_DIR} (pulando)."
  fi

  # 5.4) Descobrir e mostrar o endpoint externo do LoadBalancer (se existir)
  log "Verificando endpoint do LoadBalancer (${LB_NAMESPACE}/${LB_SERVICE_NAME})‚Ä¶"
  if kubectl -n "${LB_NAMESPACE}" get svc "${LB_SERVICE_NAME}" >/dev/null 2>&1; then
    # aguarda at√© LB expor hostname/IP ou at√© estourar timeout
    SECONDS=0
    LB_EP="$(get_lb_endpoint)"
    while [[ -z "${LB_EP}" && "${SECONDS}" -lt "${LB_WAIT_TIMEOUT}" ]]; do
      sleep 5
      LB_EP="$(get_lb_endpoint)"
    done

    if [[ -n "${LB_EP}" ]]; then
      echo
      echo "[resume] üåê Endpoint externo dispon√≠vel:"
      echo "        - HTTP : http://${LB_EP}"
      echo "        - HTTPS: https://${LB_EP}"
      echo
    else
      log "Endpoint ainda n√£o dispon√≠vel ap√≥s ${LB_WAIT_TIMEOUT}s. Voc√™ pode checar depois com:"
      echo "kubectl -n ${LB_NAMESPACE} get svc ${LB_SERVICE_NAME} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}{\"\\n\"}{.status.loadBalancer.ingress[0].ip}{\"\\n\"}'"
    fi
  else
    log "Service ${LB_NAMESPACE}/${LB_SERVICE_NAME} n√£o encontrado (ignorando descoberta de endpoint)."
  fi
else
  log "Aplica√ß√£o dos manifests desabilitada (APPLY_APP_MANIFESTS=false)."
fi

# ====== 6) Verifica√ß√µes r√°pidas ======
log "Verificando n√≥s do cluster‚Ä¶"
kubectl get nodes -o wide || true
log "Verificando namespaces b√°sicos‚Ä¶"
kubectl get ns || true
kubectl -n app get deploy,svc,job,pods || true

log "‚úÖ Ambiente retomado (EKS ativo, kubeconfig atualizado, RDS em opera√ß√£o)."
log "Se houver Service LoadBalancer (${LB_NAMESPACE}/${LB_SERVICE_NAME}), o endpoint foi mostrado acima."